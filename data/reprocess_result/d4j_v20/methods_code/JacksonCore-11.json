{"createRoot": "\n    public static ByteQuadsCanonicalizer createRoot() {\n        /* [Issue-21]: Need to use a variable seed, to thwart hash-collision\n         * based attacks.\n         */\n        long now = System.currentTimeMillis();\n        // ensure it's not 0; and might as well require to be odd so:\n        int seed = (((int) now) + ((int) (now >>> 32))) | 1;\n        return createRoot(seed);\n    }", "makeChild": "\n    public ByteQuadsCanonicalizer makeChild(int flags) {\n        return new ByteQuadsCanonicalizer(this,\n                JsonFactory.Feature.INTERN_FIELD_NAMES.enabledIn(flags),\n                _seed,\n                JsonFactory.Feature.FAIL_ON_SYMBOL_HASH_OVERFLOW.enabledIn(flags),\n                _tableInfo.get());\n    }", "release": "\n    public void release()\n    {\n        // we will try to merge if child table has new entries\n        if (_parent != null && maybeDirty()) {\n            _parent.mergeChild(new TableInfo(this));\n            /* Let's also mark this instance as dirty, so that just in\n             * case release was too early, there's no corruption of possibly shared data.\n             */\n            _hashShared = true;\n        }\n    }", "mergeChild": "\n    private void mergeChild(TableInfo childState)\n    {\n        final int childCount = childState.count;\n        TableInfo currState = _tableInfo.get();\n\n        // Should usually grow; but occasionally could also shrink if (but only if)\n        // collision list overflow ends up clearing some collision lists.\n        if (childCount == currState.count) {\n            return;\n        }\n\n        // One caveat: let's try to avoid problems with degenerate cases of documents with\n        // generated \"random\" names: for these, symbol tables would bloat indefinitely.\n        // One way to do this is to just purge tables if they grow\n        // too large, and that's what we'll do here.\n        if (childCount > MAX_ENTRIES_FOR_REUSE) {\n            // At any rate, need to clean up the tables\n            childState = TableInfo.createInitial(DEFAULT_T_SIZE);\n        }\n        _tableInfo.compareAndSet(currState, childState);\n    }", "size": "\n    public int size()\n    {\n        if (_tableInfo != null) { // root table\n            return _tableInfo.get().count;\n        }\n        // nope, child table\n        return _count;\n    }", "bucketCount": "\n    public int bucketCount() { return _hashSize; }", "maybeDirty": "\n    public boolean maybeDirty() { return !_hashShared; }", "hashSeed": "\n    public int hashSeed() { return _seed; }", "primaryCount": "\n    public int primaryCount()\n    {\n        int count = 0;\n        for (int offset = 3, end = _secondaryStart; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }", "secondaryCount": "\n    public int secondaryCount() {\n        int count = 0;\n        int offset = _secondaryStart + 3;\n        for (int end = _tertiaryStart; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }", "tertiaryCount": "\n    public int tertiaryCount() {\n        int count = 0;\n        int offset = _tertiaryStart + 3; // to 1.5x, starting point of tertiary\n        for (int end = offset + _hashSize; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }", "spilloverCount": "\n    public int spilloverCount() {\n        // difference between spillover end, start, divided by 4 (four ints per slot)\n        return (_spilloverEnd - _spilloverStart()) >> 2;\n    }", "totalCount": "\n    public int totalCount()\n    {\n        int count = 0;\n        for (int offset = 3, end = (_hashSize << 3); offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }", "toString": "\n    public String toString() {\n        int pri = primaryCount();\n        int sec = secondaryCount();\n        int tert = tertiaryCount();\n        int spill = spilloverCount();\n        int total = totalCount();\n        return String.format(\"[%s: size=%d, hashSize=%d, %d/%d/%d/%d pri/sec/ter/spill (=%s), total:%d]\",\n                getClass().getName(), _count, _hashSize,\n                pri, sec, tert, spill, total, (pri+sec+tert+spill), total);\n    }", "findName": "\n    public String findName(int q1)\n    {\n        int offset = _calcOffset(calcHash(q1));\n        // first: primary match?\n        final int[] hashArea = _hashArea;\n\n        int len = hashArea[offset+3];\n\n        if (len == 1) {\n            if (hashArea[offset] == q1) {\n                return _names[offset >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary? single slot shared by N/2 primaries\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        len = hashArea[offset2+3];\n\n        if (len == 1) {\n            if (hashArea[offset2] == q1) {\n                return _names[offset2 >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n\n        // tertiary lookup & spillovers best to offline\n        return _findSecondary(offset, q1);\n    }", "_calcOffset": "\n    private final int _calcOffset(int hash)\n    {\n        // NOTE: simple for initial impl, but we may want to interleave it a bit\n        // in near future\n        // So: first, hash into primary hash index\n        int ix = hash & (_hashSize-1);\n        // keeping in mind we have 4 ints per entry\n        return (ix << 2);\n    }", "_findSecondary": "\n    private String _findSecondary(int origOffset, int q1)\n    {\n        // tertiary area division is dynamic. First; its size is N/4 compared to\n        // primary hash size; and offsets are for 4 int slots. So to get to logical\n        // index would shift by 4. But! Tertiary area is further split into buckets,\n        // determined by shift value. And finally, from bucket back into physical offsets\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((q1 == hashArea[offset]) && (1 == len)) {\n                return _names[offset >> 2];\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        // but if tertiary full, check out spill-over area as last resort\n        // shared spillover starts at 7/8 of the main hash area\n        // (which is sized at 2 * _hashSize), so:\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((q1 == hashArea[offset]) && (1 == hashArea[offset+3])) {\n                return _names[offset >> 2];\n            }\n        }\n        return null;\n    }", "_verifyLongName": "\n    private boolean _verifyLongName(int[] q, int qlen, int spillOffset)\n    {\n        final int[] hashArea = _hashArea;\n        // spillOffset assumed to be physical index right into quad string\n        int ix = 0;\n\n        switch (qlen) {\n        default:\n            return _verifyLongName2(q, qlen, spillOffset);\n        case 8:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 7:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 6:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 5:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 4: // always at least 4\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        }\n        return true;\n    }", "_verifyLongName2": "\n    private boolean _verifyLongName2(int[] q, int qlen, int spillOffset)\n    {\n        int ix = 0;\n        do {\n            if (q[ix++] != _hashArea[spillOffset++]) {\n                return false;\n            }\n        } while (ix < qlen);\n        return true;\n    }", "addName": "\n    public String addName(String name, int q1) {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int offset = _findOffsetForAdd(calcHash(q1));\n        _hashArea[offset] = q1;\n        _hashArea[offset+3] = 1;\n        _names[offset >> 2] = name;\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }", "_verifyNeedForRehash": "\n    private void _verifyNeedForRehash() {\n        // Yes if above 80%, or above 50% AND have ~1% spill-overs\n        if (_count > (_hashSize >> 1)) { // over 50%\n            int spillCount = (_spilloverEnd - _spilloverStart()) >> 2;\n            if ((spillCount > (1 + _count >> 7))\n                    || (_count > (_hashSize * 0.80))) {\n                _needRehash = true;\n            }\n        }\n    }", "_verifySharing": "\n    private void _verifySharing()\n    {\n        if (_hashShared) {\n            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);\n            _names = Arrays.copyOf(_names, _names.length);\n            _hashShared = false;\n            // 09-Sep-2015, tatu: As per [jackson-core#216], also need to ensure\n            //    we rehash as needed, as need-rehash flag is not copied from parent\n        }\n        if (_needRehash) {\n            rehash();\n        }\n    }", "_findOffsetForAdd": "\n    private int _findOffsetForAdd(int hash)\n    {\n        // first, check the primary:\n        int offset = _calcOffset(hash);\n        final int[] hashArea = _hashArea;\n        if (hashArea[offset+3] == 0) {\n//System.err.printf(\" PRImary slot #%d, hash %X\\n\", (offset>>2), hash & 0x7F);\n            return offset;\n        }\n        // then secondary\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n        if (hashArea[offset2+3] == 0) {\n//System.err.printf(\" SECondary slot #%d (start x%X), hash %X\\n\",(offset >> 3), _secondaryStart, (hash & 0x7F));\n            return offset2;\n        }\n        // if not, tertiary?\n\n        offset2 = _tertiaryStart + ((offset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset2 + bucketSize; offset2 < end; offset2 += 4) {\n            if (hashArea[offset2+3] == 0) {\n//System.err.printf(\" TERtiary slot x%X (from x%X, start x%X), hash %X.\\n\", offset2, ((offset >> (_tertiaryShift + 2)) << _tertiaryShift), _tertiaryStart, (hash & 0x7F));\n                return offset2;\n            }\n        }\n\n        // and if even tertiary full, append at the end of spill area\n        offset = _spilloverEnd;\n        _spilloverEnd += 4;\n\n//System.err.printf(\" SPIll-over at x%X; start x%X; end x%X, hash %X\\n\", offset, _spilloverStart(), _hashArea.length, (hash & 0x7F));\n        \n        // one caveat: in the unlikely event if spill-over filling up,\n        // check if that could be considered a DoS attack; handle appropriately\n        // (NOTE: approximate for now; we could verify details if that becomes necessary)\n        /* 31-Jul-2015, tatu: Note that spillover area does NOT end at end of array,\n         *   since \"long names\" area follows. Instead, need to calculate from hash size.\n         */\n        final int end = (_hashSize << 3);\n        if (_spilloverEnd >= end) {\n            if (_failOnDoS) {\n                _reportTooManyCollisions();\n            }\n            // and if we didn't fail, we'll simply force rehash for next add\n            // (which, in turn, may double up or nuke contents, depending on size etc)\n            _needRehash = true;\n        }\n        return offset;\n    }", "_appendLongName": "\n    private int _appendLongName(int[] quads, int qlen)\n    {\n        int start = _longNameOffset;\n        \n        // note: at this point we must already be shared. But may not have enough space\n        if ((start + qlen) > _hashArea.length) {\n            // try to increment in reasonable chunks; at least space that we need\n            int toAdd = (start + qlen) - _hashArea.length;\n            // but at least 1/8 of regular hash area size or 16kB (whichever smaller)\n            int minAdd = Math.min(4096, _hashSize);\n\n            int newSize = _hashArea.length + Math.max(toAdd, minAdd);\n            _hashArea = Arrays.copyOf(_hashArea, newSize);\n        }\n        System.arraycopy(quads, 0, _hashArea, start, qlen);\n        _longNameOffset += qlen;\n        return start;\n    }", "calcHash": "\n    public int calcHash(int q1)\n    {\n        int hash = q1 ^ _seed;\n        /* 29-Mar-2015, tatu: Earlier used 15 + 9 right shifts, which worked ok\n         *    except for one specific problem case: numbers. So needed to make sure\n         *    that all 4 least-significant bits participate in hash. Couple of ways\n         *    to work it out, but this is the simplest, fast and seems to do ok.\n         */\n        hash += (hash >>> 16); // to xor hi- and low- 16-bits\n        hash ^= (hash << 3); // shuffle back a bit\n        hash += (hash >>> 12); // and bit more\n        return hash;\n    }", "rehash": "\n    private void rehash()\n    {\n        _needRehash = false;\n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _hashShared = false;\n\n        // And then we can first deal with the main hash area. Since we are expanding\n        // linearly (double up), we know there'll be no collisions during this phase.\n        final int[] oldHashArea = _hashArea;\n        final String[] oldNames = _names;\n        final int oldSize = _hashSize;\n        final int oldCount = _count;\n        final int newSize = oldSize + oldSize;\n        final int oldEnd = _spilloverEnd;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newSize > MAX_T_SIZE) {\n            nukeSymbols(true);\n            return;\n        }\n        // double up main hash area, but do not expand long-name area:\n        _hashArea = new int[oldHashArea.length + (oldSize<<3)];\n        _hashSize = newSize;\n        _secondaryStart = (newSize << 2); // 4 ints per entry\n        _tertiaryStart = _secondaryStart + (_secondaryStart >> 1); // right after secondary\n        _tertiaryShift = _calcTertiaryShift(newSize);\n        \n        // and simply double up name array\n        _names = new String[oldNames.length << 1];\n        nukeSymbols(false);\n\n        // Plus we can scan only through the primary hash area, looking for non-empty\n        // slots, without worrying about ordering. This should never reduce priority\n        // of existing entries: primaries remain primaries; however, due to increased\n        // space, secondaries may become primaries etc\n\n        int copyCount = 0;\n        int[] q = new int[16];\n        for (int offset = 0, end = oldEnd; offset < end; offset += 4) {\n            int len = oldHashArea[offset+3];\n            if (len == 0) { // empty slot, skip\n                continue;\n            }\n            ++copyCount;\n            String name = oldNames[offset>>2];\n            switch (len) {\n            case 1:\n                q[0] = oldHashArea[offset];\n                addName(name, q, 1);\n                break;\n            case 2:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                addName(name, q, 2);\n                break;\n            case 3:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                q[2] = oldHashArea[offset+2];\n                addName(name, q, 3);\n                break;\n            default:\n                if (len > q.length) {\n                    q = new int[len];\n                }\n                // #0 is hash, #1 offset\n                int qoff = oldHashArea[offset+1];\n                System.arraycopy(oldHashArea, qoff, q, 0, len);\n                addName(name, q, len);\n                break;\n            }\n        }\n\n        // Sanity checks: since corruption difficult to detect, assert explicitly\n        // with production code\n        if (copyCount != oldCount) {\n            throw new IllegalStateException(\"Failed rehash(): old count=\"+oldCount+\", copyCount=\"+copyCount);\n        }\n    }", "nukeSymbols": "\n    private void nukeSymbols(boolean fill) {\n        _count = 0;\n        // reset spill-over to empty (starting at 7/8 of hash area)\n        _spilloverEnd = _spilloverStart();\n        // and long name area to empty, starting immediately after hash area\n        _longNameOffset = _hashSize << 3;\n        if (fill) {\n            Arrays.fill(_hashArea, 0);\n            Arrays.fill(_names, null);\n        }\n    }", "_spilloverStart": "\n    private final int _spilloverStart() {\n        // we'll need slot at 1.75x of hashSize, but with 4-ints per slot.\n        // So basically multiply by 7\n        int offset = _hashSize;\n        return (offset << 3) - offset;\n    }", "_reportTooManyCollisions": "\n    protected void _reportTooManyCollisions()\n    {\n        // First: do not fuzz about small symbol tables; may get balanced by doubling up\n        if (_hashSize <= 1024) { // would have spill-over area of 128 entries\n            return;\n        }\n        throw new IllegalStateException(\"Spill-over slots in symbol table with \"+_count\n                +\" entries, hash area of \"+_hashSize+\" slots is now full (all \"\n                +(_hashSize >> 3)+\" slots -- suspect a DoS attack based on hash collisions.\"\n                +\" You can disable the check via `JsonFactory.Feature.FAIL_ON_SYMBOL_HASH_OVERFLOW`\");\n    }", "_calcTertiaryShift": "\n    static int _calcTertiaryShift(int primarySlots)\n    {\n        // first: we only get 1/4 of slots of primary, to divide\n        int tertSlots = (primarySlots) >> 2;\n        \n        // default is for buckets of 4 slots (each 4 ints, i.e. 1 << 4)\n        if (tertSlots < 64) {\n            return 4;\n        }\n        if (tertSlots <= 256) { // buckets of 8 slots (up to 256 == 32 x 8)\n            return 5;\n        }\n        if (tertSlots <= 1024) { // buckets of 16 slots (up to 1024 == 64 x 16)\n            return 6;\n        }\n        // and biggest buckets have 32 slots\n        return 7;\n    }", "createInitial": "\n        public static TableInfo createInitial(int sz) {\n            int hashAreaSize = sz << 3;\n            int tertShift = _calcTertiaryShift(sz);\n\n            return new TableInfo(sz, // hashSize\n                    0, // count\n                    tertShift,\n                    new int[hashAreaSize], // mainHash, 2x slots, 4 ints per slot\n                    new String[sz << 1], // names == 2x slots\n                    hashAreaSize - sz, // at 7/8 of the total area\n                    hashAreaSize // longNameOffset, immediately after main hashes\n            );\n        }"}