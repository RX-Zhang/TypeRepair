{"close": "\n    public void close() throws IOException {\n        is.close();\n    }", "getRecordSize": "\n    public int getRecordSize() {\n        return recordSize;\n    }", "available": "\n    public int available() throws IOException {\n        if (isDirectory()) {\n            return 0;\n        }\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }", "skip": "\n    public long skip(final long n) throws IOException {\n        if (n <= 0 || isDirectory()) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }", "markSupported": "\n    public boolean markSupported() {\n        return false;\n    }", "mark": "\n    public void mark(final int markLimit) {\n    }", "reset": "\n    public synchronized void reset() {\n    }", "getNextTarEntry": "\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            IOUtils.skip(this, Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        final byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (final IllegalArgumentException e) {\n            throw new IOException(\"Error detected parsing the header\", e);\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            final byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            final byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isGlobalPaxHeader()){ // Process Global Pax headers\n            readGlobalPaxHeaders();\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        } else if (!globalPaxHeaders.isEmpty()) {\n            applyPaxHeadersToCurrentEntry(globalPaxHeaders);\n        }\n\n        if (currEntry.isOldGNUSparse()){ // Process sparse files\n            readOldGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }", "skipRecordPadding": "\n    private void skipRecordPadding() throws IOException {\n        if (!isDirectory() && this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            final long numRecords = (this.entrySize / this.recordSize) + 1;\n            final long padding = (numRecords * this.recordSize) - this.entrySize;\n            final long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }", "getLongNameData": "\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        final ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            final byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }", "getRecord": "\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }", "isEOFRecord": "\n    protected boolean isEOFRecord(final byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }", "readRecord": "\n    protected byte[] readRecord() throws IOException {\n\n        final byte[] record = new byte[recordSize];\n\n        final int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }", "readGlobalPaxHeaders": "\n    private void readGlobalPaxHeaders() throws IOException {\n        globalPaxHeaders = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n    }", "paxHeaders": "\n    private void paxHeaders() throws IOException{\n        final Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }", "parsePaxHeaders": "\n    Map<String, String> parsePaxHeaders(final InputStream i)\n        throws IOException {\n        final Map<String, String> headers = new HashMap<String, String>(globalPaxHeaders);\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){\n                    // Get keyword\n                    final ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            final String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            if (restLen == 1) { // only NL\n                                headers.remove(keyword);\n                            } else {\n                                final byte[] rest = new byte[restLen];\n                                final int got = IOUtils.readFully(i, rest);\n                                if (got != restLen) {\n                                    throw new IOException(\"Failed to read \"\n                                                          + \"Paxheader. Expected \"\n                                                          + restLen\n                                                          + \" bytes, read \"\n                                                          + got);\n                                }\n                                // Drop trailing NL\n                                final String value = new String(rest, 0,\n                                                          restLen - 1, CharsetNames.UTF_8);\n                                headers.put(keyword, value);\n                            }\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }", "applyPaxHeadersToCurrentEntry": "\n    private void applyPaxHeadersToCurrentEntry(final Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         *\n         * GNU sparse files use additional members, we use\n         * GNU.sparse.size to detect the 0.0 and 0.1 versions and\n         * GNU.sparse.realsize for 1.0.\n         *\n         * star files use additional members of which we use\n         * SCHILY.filetype in order to detect star sparse files.\n         */\n        for (final Entry<String, String> ent : headers.entrySet()){\n            final String key = ent.getKey();\n            final String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Long.parseLong(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Long.parseLong(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            } else if (\"GNU.sparse.size\".equals(key)) {\n                currEntry.fillGNUSparse0xData(headers);\n            } else if (\"GNU.sparse.realsize\".equals(key)) {\n                currEntry.fillGNUSparse1xData(headers);\n            } else if (\"SCHILY.filetype\".equals(key) && \"sparse\".equals(val)) {\n                currEntry.fillStarSparseData(headers);\n            }\n        }\n    }", "readOldGNUSparse": "\n    private void readOldGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                final byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }", "isDirectory": "\n    private boolean isDirectory() {\n        return currEntry != null && currEntry.isDirectory();\n    }", "getNextEntry": "\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }", "tryToConsumeSecondEOFRecord": "\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        final boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }", "read": "\n    public int read(final byte[] buf, final int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || isDirectory() || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }", "canReadEntryData": "\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            final TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isSparse();\n        }\n        return false;\n    }", "getCurrentEntry": "\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }", "setCurrentEntry": "\n    protected final void setCurrentEntry(final TarArchiveEntry e) {\n        currEntry = e;\n    }", "isAtEOF": "\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }", "setAtEOF": "\n    protected final void setAtEOF(final boolean b) {\n        hasHitEOF = b;\n    }", "consumeRemainderOfLastBlock": "\n    private void consumeRemainderOfLastBlock() throws IOException {\n        final long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            final long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }", "matches": "\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }"}